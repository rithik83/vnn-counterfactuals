from maraboupy import Marabou
import numpy as np
from torchvision import datasets, transforms

train_set = datasets.MNIST('./data', train=True, download=True)
test_set = datasets.MNIST('./data', train=False, download=True)

train_set_array = train_set.data.numpy()
test_set_array = test_set.data.numpy()

print(train_set_array[0:1].flatten().shape)

options = Marabou.createOptions(verbosity = 0, timeoutInSeconds=10)

filename = 'models/classically_trained.onnx'
# filename = 'models/adv_pgd_strong.onnx'
# filename = 'models/adv_pgd_medium.onnx'
# filename = 'models/adv_pgd_weak.onnx'
network = Marabou.read_onnx(filename)

inputVars = network.inputVars[0][0]
outputVars = network.outputVars[0][0]

# print("inputVars shape: ", inputVars.shape)
# print("outputVars shape: ", outputVars.shape)
# print("outputVars: ", outputVars)

epsilon = 0.1
index = 4521
# image = train_set_array[index: index + 1].flatten() / 255
# correct_class = train_set.targets.numpy()[index]

image = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00013379228525991493, 0.0, 0.0, 3.726289778569481e-5, 6.897724556438334e-5, 0.0, 0.00017839170891420508, 0.0, 0.0, 5.974771329420037e-6, 1.6211687762890392e-5, 9.604505589777546e-5, 0.0, 0.0, 0.0, 0.0, 0.0, 4.093175166417496e-5, 0.0, 0.0, 0.0, 1.7359070147904278e-5, 1.1566353941816488e-5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0001283669007534627, 0.00041157771047437567, 0.0004503499243583065, 4.951389075722541e-5, 8.905387789127331e-6, 0.0, 0.0, 0.00037903353386354867, 0.2169728426632303, 0.0004971833228628384, 0.24171676532723924, 0.1120997419519171, 0.0, 0.00017283297966059764, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.3347041422994153e-5, 0.0, 0.0, 0.0, 0.0004036892252770486, 0.000268500159290852, 2.1133781978278357e-5, 0.0004886716029432137, 1.0, 0.07392710902532319, 0.08598517097017364, 0.14402009789882939, 0.000545416644308716, 0.4634418198949952, 0.00035316068335669115, 0.0, 0.0003972822389187059, 4.9970310101343784e-5, 4.581235061777989e-5, 0.0, 7.804075417516247e-5, 0.3297020479761283, 0.00033766292710788544, 0.194419710966626, 0.0, 8.408172452618602e-5, 9.037678191816668e-5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0004966073734976817, 0.00020815279551607095, 0.00024291554348019424, 0.0, 0.018012721931144404, 0.0005641946392861428, 0.566857904938276, 0.0, 0.0002601587412937079, 0.03256777273362338, 4.570282471831888e-5, 0.0, 0.0, 0.0, 0.0006767217044834978, 0.0, 0.0002647585695958696, 0.43744882767996746, 0.7760352786095712, 9.027512560351171e-5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0002909167624238762, 0.0, 0.0, 0.0, 0.00025213238152355186, 0.00035965000645228433, 0.0, 0.0, 0.0, 0.0007695720825722674, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00011005394846870325, 0.00038221788381633817, 0.0, 0.00017555323347551166, 0.0, 0.0, 0.0, 0.0, 0.6529063198380565, 0.0, 0.0, 2.4297694835695438e-5, 0.0, 0.00026137976647078176, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 6.784711640648312e-5, 0.0, 0.00021665052154276057, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00026060784684887043, 0.0, 0.00041998120013886364, 0.17327570853014304, 0.0, 0.0, 0.07603884651724269, 0.543877478688193, 3.750660812329443e-5, 4.764614063788031e-5, 2.587339004094247e-5, 0.0, 0.00023061439119373973, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.14567826943169654, 0.4345622860938543, 0.3016640852667923, 0.03496434469606383, 0.0, 0.0, 0.004038049133056284, 0.043727867552081426, 0.2195758478159783, 0.5380667038689377, 0.8230017101722746, 0.8231366733817926, 0.9565759399890819, 0.8227377735040512, 0.8220989222564329, 0.6662827914440567, 0.0, 0.0, 0.0, 0.0, 0.00010246093443129213, 0.0005604531314020279, 0.0, 0.0, 0.0, 0.0, 0.06598283896275026, 0.5929143952900123, 0.8852760562605887, 0.9918833351390465, 0.9918951986735144, 0.8777208018527708, 0.06291521705526244, 0.050798190607183234, 0.5770640559582163, 0.9957824827152314, 0.9924187895856532, 0.9912331642421004, 0.9687767208608697, 0.737059257091796, 0.7421103313542727, 0.7415653084848591, 0.7399693200767067, 0.4354810658179026, 0.0, 0.0, 0.0, 0.00029316447018936737, 0.000142793936014641, 0.012886096205837794, 0.00011599591416597833, 0.0, 0.0, 0.03444369424880433, 0.8946189425483034, 0.9886561514801885, 0.6460630260502428, 0.5248153840951784, 0.6538946057097248, 0.9606584177881624, 0.7454722009520462, 0.725580097579699, 0.960368604639516, 0.6711720299112203, 0.19588287530117823, 0.13795283816562734, 0.12232715441862141, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00024736524887885024, 0.0, 0.0, 0.0, 0.0, 0.30881431986960933, 0.9931797883238829, 0.7993226818595821, 0.0, 0.0, 0.0, 0.23488131280052843, 0.8142485072312569, 0.584475360304646, 0.18333002160231537, 1.6671192315698136e-5, 0.00011770956614145682, 0.00030500226712320004, 7.556684722658247e-5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00016605982991677593, 4.104853469470982e-5, 0.0, 0.7845542236975285, 0.993002750472629, 0.1730138275054988, 0.0, 0.0, 0.0, 0.0, 0.03905726649773861, 0.03926361721501478, 0.0005257460225948307, 0.000337983185727353, 0.0, 0.0, 1.0839617243618705e-5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.995509510645207e-5, 0.0, 0.0, 0.0005187125267402735, 0.0, 0.00031292642870539567, 0.0, 0.0, 0.824224632861024, 0.9912498664842071, 0.39534895805709425, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00030952569213695826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00017204599766955654, 0.0001649647050726344, 0.0, 1.0205022590525914e-5, 0.0, 0.0, 0.3914655494740547, 0.9920743428412198, 0.9874429038463322, 0.40291176107339705, 0.01569688751195505, 0.0, 0.0, 0.0, 0.00035313193329784555, 0.00010153982802876272, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003781982750515454, 0.0, 0.0, 0.0, 0.0, 0.0, 9.981451059866225e-5, 0.0, 0.0, 0.0, 2.4916385427786736e-5, 0.0, 0.010899978699543025, 0.5809114347125433, 0.9958913831735946, 0.9962836867428516, 0.5848188062953762, 0.10199155154435785, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00036609563449019333, 0.0, 0.0, 0.00015131171330722283, 6.268565884965937e-5, 0.0, 0.0, 0.0, 0.0, 0.00043820474822859983, 0.0002632161900692154, 2.4763098190305757e-5, 0.00015445684612132028, 0.008285406791000026, 0.3581253487089762, 0.8113295226181879, 0.9930090306490865, 0.9843197768934994, 0.544275131392091, 0.12559757919235068, 0.0005302586150719435, 1.575189035065705e-5, 0.0, 0.0003456031276527938, 0.0, 0.0006441551959142089, 0.0, 0.0, 0.0, 0.18107370344849472, 0.0002622923891285609, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0002951733846421121, 0.0, 0.09705817046316659, 0.1974450359110717, 0.13908951147780338, 0.0, 0.13303832735387872, 0.39599980458505, 0.8741866681435865, 0.9924092566301199, 0.9219020594071061, 0.1851760707136772, 0.00041809935664787194, 0.0, 0.0, 0.0, 9.279150983638822e-5, 0.0003895790822753043, 0.0, 0.0, 0.11975587900259797, 0.00011583360503573199, 3.859845237457194e-5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0006799011420298485, 0.625573552026008, 0.699154405582228, 0.37678901220734534, 8.147950640704883e-6, 0.032467561719853516, 0.0, 0.1251025010488698, 0.6197003409115663, 0.995461865333012, 0.9211224808459187, 0.3105136312281853, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4239527135895922, 0.00020795794955483866, 0.0, 3.394428024421359e-5, 0.0, 0.0, 0.0, 0.00030120816068119894, 0.0005974259784125024, 0.00018507053332541548, 0.5719701853506752, 0.5013514932427278, 0.6823157402242658, 1.0, 0.35217732039388155, 0.0007363199876854196, 0.0004646750398242148, 0.027905235083366998, 0.3016609010598523, 0.9891761913823053, 0.9927643946205692, 0.5008568922608462, 0.012455891350171633, 0.000149517715908587, 6.993849756327108e-5, 6.183921525371264e-5, 0.0001468539127235999, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.2419387460104193e-5, 0.0, 2.600972293294035e-5, 0.0, 0.0, 0.7128527532107902, 0.1141683853707478, 0.5848885668210002, 0.3452437264066463, 0.0, 0.3303685776508209, 0.3199777936119108, 0.000299380745695089, 0.0, 0.32444581281481233, 0.8672670455746323, 0.9920699167495852, 0.41488810333088993, 0.0, 0.0, 0.0001423757623342681, 0.0, 0.0, 0.0, 0.0, 0.000269847025629133, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8912383546063524, 0.12590805093185645, 0.0, 0.0002604955070637516, 0.00019063908912357876, 0.0, 0.0004387451293951017, 0.0, 0.0, 0.0, 0.26256771561861736, 0.9556138193048563, 0.5808220683835655, 0.0, 0.0, 0.00022549240422904405, 0.0, 0.0, 0.0, 0.0, 0.0003134704729745863, 0.0, 0.0, 2.800699858198641e-5, 0.0, 0.0, 0.0, 0.0, 0.9999011894498835, 0.8394650457062424, 2.242201317130821e-5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0002799829704599688, 0.0, 0.0, 0.6276758090979442, 0.9328486300849508, 0.0, 0.0002527502849261509, 7.875789469835581e-5, 0.0, 0.0, 0.00012034697829221841, 0.0, 0.0, 0.0, 0.00031124885168765104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.43182471394543603, 0.9924222333568623, 0.8191498486564286, 0.5285926687689663, 0.2622773259769248, 0.13630456341693842, 0.1379814684673151, 0.13820121226912593, 0.1374121111672223, 0.5221809175191612, 0.8436719421838242, 0.963505380534745, 0.8830153069863211, 0.0002315375466423575, 0.00010901563091465506, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003180746072976035, 0.00012220081516716165, 0.0, 0.0, 0.0, 0.05525004443977861, 0.5885582434050074, 0.9963725329836646, 0.9954875905551744, 0.9953674288701277, 0.9962916953556618, 0.9970725189539883, 0.9966911514753949, 0.9954714536257361, 0.9961127358590673, 0.996636456657641, 0.9096029219494612, 0.35230138866313343, 0.0002868948571631336, 0.0, 5.6549674081907145e-5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00012273209122213303, 0.0, 0.00011367838123987895, 7.329087111429544e-5, 0.00024538370653317545, 0.00034295684172320763, 0.019995847843474197, 0.4275930162622441, 0.4262780818691446, 0.692848674054294, 0.8164790097552392, 0.816070836542028, 0.8151939444248729, 0.8160119300445798, 0.584530829123999, 0.42407796506008627, 0.027266054451104228, 0.0002249887096695602, 0.0005383626004913822, 2.7777364448411393e-5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.0540201322291914e-5, 0.0, 4.082863854273455e-5, 0.0, 0.000326901936205104, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0005296953138895333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.5268183597072495e-5, 0.0, 0.0, 0.0, 0.0, 0.0, 5.501987307070522e-5, 0.0, 0.0003589034095966781, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 5.298674896039302e-5, 5.158163439773489e-5, 0.000255357659625588, 0.0, 0.00016540615370104207, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.29519654669275e-5, 0.0, 2.1425496015581302e-5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00012573849699037964, 0.00015226991927193013, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00018168004137260134, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00033890280810737754, 0.0, 0.0, 0.0, 1.0914371250692058e-5, 0.0, 0.0, 6.0403678253351246e-5]
correct_class = 6

print("correct class: ", correct_class)


for i in range(len(inputVars)):
    network.setLowerBound(inputVars[i], max(image[i] - epsilon, 0))
    network.setUpperBound(inputVars[i], min(image[i] + epsilon, 1))

margin = -0.00001

for i in range(len(outputVars)):
  print("i: ", i)
  if i != correct_class:
    network.addMaxConstraint(set(outputVars), outputVars[i])
    network.addInequality([outputVars[correct_class], outputVars[i]], [1, -1], margin)
    exit_code, vals, stats = network.solve(verbose = False, options = options)

    print("satisfiability? ", exit_code)

    # if solution found, break
    if len(vals) > 0:
      for j, var in enumerate(outputVars):
        print(f"output {j}: {vals[var]}")
      print(f"maxclass: {i}")
      inputPoint = np.zeros((1, 784))
      for j, var in enumerate(inputVars):
        inputPoint[0][j] = vals[j]
      
      meval = network.evaluateWithMarabou(inputPoint, options = options)[0]
      onnxeval = network.evaluateWithoutMarabou(inputPoint)[0]

      print("marabou eval: ", meval)
      print("onnx eval: ", onnxeval)
      
      break










# print("\nConvolutional Network with Max Pool Example")
# filename = 'resources/classic_cnn.onnx'
# network = Marabou.read_onnx(filename)

# # # %%
# # Get the input and output variable numbers; [0] since first dimension is batch size
# inputVars = network.inputVars[0]
# outputVars = network.outputVars[0]

# # %% 
# # Test Marabou equations against onnxruntime at an example input point
# inputPoint = np.zeros(inputVars.shape)
# print("inputvars shape: ", inputVars.shape)
# marabouEval = network.evaluateWithMarabou([inputPoint], options = options)[0]
# onnxEval = network.evaluateWithoutMarabou([inputPoint])[0]

# # # %%
# # The two evaluations should produce the same result
# print("Marabou Evaluation:")
# print(marabouEval)
# print("\nONNX Evaluation:")
# print(onnxEval)
# print("\nDifference:")
# print(onnxEval - marabouEval)
# assert max(abs(onnxEval - marabouEval).flatten()) < 1e-3


# print("\nConvolutional Network Example")
# filename = 'resources/KJ_TinyTaxiNet.onnx'
# network = Marabou.read_onnx(filename)

# # %%
# # Get the input and output variable numbers; [0] since first dimension is batch size
# inputVars = network.inputVars[0][0]
# outputVars = network.outputVars[0][0]

# # %%
# # Setup a local robustness query
# delta = 0.03
# for h in range(inputVars.shape[0]):
#     for w in range(inputVars.shape[1]):
#         network.setLowerBound(inputVars[h][w][0], 0.5-delta)
#         network.setUpperBound(inputVars[h][w][0], 0.5+delta)

# # %%
# # Set output bounds
# network.setLowerBound(outputVars[0], 6.0)

# # %%
# # Call to Marabou solver (should be SAT)
# print("Check query with less restrictive output constraint (Should be SAT)")
# exitCode, vals, stats = network.solve(options = options)
# assert( exitCode == "sat")
# assert len(vals) > 0

# print("vals: ", vals)

# # %%
# # Set more restrictive output bounds
# network.setLowerBound(outputVars[0], 6.55)

# # %%
# # Call to Marabou solver (should be UNSAT)
# print("Check query with more restrictive output constraint (Should be UNSAT)")
# exitCode, vals, stats = network.solve(options = options)
# assert( exitCode == "unsat")
# assert len(vals) == 0